{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b9fa63-0ee2-4f84-b8f8-a4074211de5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!huggingface-cli login\n",
    "# Enter the HF access token generated from the HuggingFace account page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d24509a-302b-4108-bd12-5f0093421337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datasets\n",
    "import transformers\n",
    "import peft\n",
    "import trl\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dcc97c3-4162-4c7b-a136-d1aa7f58204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EFFICIENT_TRAINING = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d45fb28a-c115-4504-957f-b938b5d63994",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_dtype = getattr(torch, \"float16\")\n",
    "quant_config = transformers.BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=compute_dtype, # Run computations in 16-bit float\n",
    "    bnb_4bit_use_double_quant=False, # Use True for additional memory saving\n",
    ") if EFFICIENT_TRAINING else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d290d9ba-a5db-4e66-84e8-6ada625ef942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "313745e1face459a9fc61eb9bd3028b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model_name = \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "base_model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    quantization_config=quant_config if EFFICIENT_TRAINING else None,\n",
    "    device_map={\"\": 0}\n",
    ")\n",
    "if EFFICIENT_TRAINING:\n",
    "    base_model.config.use_cache = False\n",
    "    base_model.config.pretraining_tp = 1 # A value other than 1 uses a slower, more accurate linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f3d12ed-b13b-409a-9fe8-fdde95816f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "762c06ff938c42f0a45567f33dbe6dc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/479M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/jk23541/qwem7b_4bit_s1/commit/895bd6db51f2133854e6117f428d2505a934ebbc', commit_message='Upload model', commit_description='', oid='895bd6db51f2133854e6117f428d2505a934ebbc', pr_url=None, repo_url=RepoUrl('https://huggingface.co/jk23541/qwem7b_4bit_s1', endpoint='https://huggingface.co', repo_type='model', repo_id='jk23541/qwem7b_4bit_s1'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = peft.PeftModel.from_pretrained(base_model, \"qwem7b_4bit_s1\")\n",
    "\n",
    "model.push_to_hub(\"jk23541/qwem7b_4bit_s1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea702d7-710f-4e50-97f4-eac76551810a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (main venv)",
   "language": "python",
   "name": "main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
